<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>sparsesurv.cv &mdash; sparsesurv  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            sparsesurv
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../sparsesurv_api/sparsesurv.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../references.html">References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">sparsesurv</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">sparsesurv.cv</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for sparsesurv.cv</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numbers</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Real</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">TypeVar</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">celer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.typing</span> <span class="k">as</span> <span class="nn">npt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">joblib</span> <span class="kn">import</span> <span class="n">effective_n_jobs</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">sparse</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model._coordinate_descent</span> <span class="kn">import</span> <span class="n">_alpha_grid</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">check_cv</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.parallel</span> <span class="kn">import</span> <span class="n">Parallel</span><span class="p">,</span> <span class="n">delayed</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_sample_weight</span><span class="p">,</span>
    <span class="n">check_consistent_length</span><span class="p">,</span>
    <span class="n">check_scalar</span><span class="p">,</span>
    <span class="n">column_or_1d</span><span class="p">,</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">._base</span> <span class="kn">import</span> <span class="n">SurvivalMixin</span>
<span class="kn">from</span> <span class="nn">.compat</span> <span class="kn">import</span> <span class="n">BASELINE_HAZARD_FACTORY</span><span class="p">,</span> <span class="n">CVSCORERFACTORY</span><span class="p">,</span> <span class="n">LOSS_FACTORY</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="n">_path_predictions</span><span class="p">,</span> <span class="n">inverse_transform_survival_kd</span>

<span class="n">Self</span> <span class="o">=</span> <span class="n">TypeVar</span><span class="p">(</span><span class="s2">&quot;Self&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="BaseKDSurv"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.BaseKDSurv">[docs]</a><span class="k">class</span> <span class="nc">BaseKDSurv</span><span class="p">(</span><span class="n">SurvivalMixin</span><span class="p">,</span> <span class="n">celer</span><span class="o">.</span><span class="n">ElasticNetCV</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Parent class to fit distilled sparse semi-parametric right-censored survival</span>
<span class="sd">        models using cross validation.</span>

<span class="sd">    Notes:</span>
<span class="sd">        This class is largely adapted from the `ElasticNetCV` implementations</span>
<span class="sd">        in `sklearn` and `celer`.</span>

<span class="sd">    See Also:</span>
<span class="sd">        sklearn.linear_model.ElasticNetCV</span>
<span class="sd">        celer.ElasticNetCV</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="BaseKDSurv.__init__"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.BaseKDSurv.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">l1_ratio</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">n_alphas</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="n">p0</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">prune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stratify_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">shuffle_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cv_score_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">,</span>
        <span class="n">max_coef</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">alpha_type</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Args:</span>
<span class="sd">            l1_ratio (Union[float, List[float]], optional): Float between 0 and 1 passed</span>
<span class="sd">                to ElasticNet (scaling between l1 and l2 penalties). For ``l1_ratio = 0``</span>
<span class="sd">                the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.</span>
<span class="sd">                For ``0 &lt; l1_ratio &lt; 1``, the penalty is a combination of L1 and L2.</span>
<span class="sd">                This parameter can be a list, in which case the different values are tested</span>
<span class="sd">                by cross-validation and the one giving the best prediction score is used.</span>
<span class="sd">                Note that a good choice of list of values for l1_ratio is often to put more</span>
<span class="sd">                values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge),</span>
<span class="sd">                as in ``[.1, .5, .7, .9, .95, .99, 1]``. Defaults to 1.0.</span>
<span class="sd">            eps (float, optional): Length of the path. ``eps=1e-3`` means that</span>
<span class="sd">                ``alpha_min / alpha_max = 1e-3``. Defaults to 1e-3.</span>
<span class="sd">            n_alphas (int, optional): Number of alphas along the regularization path,</span>
<span class="sd">                used for each l1_ratio. Defaults to 100.</span>
<span class="sd">            max_iter (int, optional): The maximum number of iterations. Defaults to 100.</span>
<span class="sd">            tol (float, optional): The tolerance for the optimization: if the updates are</span>
<span class="sd">                smaller than ``tol``, the optimization code checks the dual gap for optimality</span>
<span class="sd">                and continues until it is smaller than ``tol``. Defaults to 1e-4.</span>
<span class="sd">            cv (int, optional): Number of folds to perform to select hyperparameters.</span>
<span class="sd">                Defaults to 5. See also `stratify_cv`.</span>
<span class="sd">            verbose (int, optional): Degree of verbosity. Defaults to 0.</span>
<span class="sd">            max_epochs (int, optional): Maximum number of coordinate descent epochs when</span>
<span class="sd">                solving a subproblem. Defaults to 50000.</span>
<span class="sd">            p0 (int, optional): Number of features in the first working set. Defaults to 10.</span>
<span class="sd">            prune (bool, optional): Whether to use pruning when growing the working sets.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            n_jobs (Optional[int], optional): Number of CPUs to use during the cross validation.</span>
<span class="sd">                ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">                ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">                for more details. Defaults to None.</span>
<span class="sd">            stratify_cv (bool, optional): Whether to perform the cross-validation stratified</span>
<span class="sd">                on the event indicator or not. Defaults to True.</span>
<span class="sd">            seed (Optional[int], optional): Random seed. Defaults to 42.</span>
<span class="sd">            shuffle_cv (bool, optional): Whether to perform shuffling to generate</span>
<span class="sd">                CV fold indices. Defaults to False.</span>
<span class="sd">            cv_score_method (str, optional): Which scoring method to use. Defaults to &quot;linear_predictor&quot;.</span>
<span class="sd">                Must be one of &quot;linear_predictor&quot;, &quot;mse&quot;, &quot;basic&quot; and &quot;vvh&quot;.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            max_coef (float, optional): Maximum number of non-zero covariates to be selected</span>
<span class="sd">                with chosen optimal regularization hyperparameter. Defaults to np.inf.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            alpha_type (str, optional): How to select the optimal regularization hyperparameter. Defaults to &quot;min&quot;.</span>
<span class="sd">                Must be one of &quot;min&quot;, &quot;1se&quot; and &quot;pcvl&quot;. See Notes.</span>



<span class="sd">        Notes:</span>
<span class="sd">            `cv_score_method`:</span>
<span class="sd">                Decides how the score which is used to select the optimal</span>
<span class="sd">                regularization hyperparameter is selected. The `basic`</span>
<span class="sd">                approach may suffer from issues with small event sizes or</span>
<span class="sd">                for large number of folds [1]. Meanwhile, the `mse` approach</span>
<span class="sd">                may yield good teacher-student fidelity, but suboptimal</span>
<span class="sd">                survival predictions.</span>

<span class="sd">                - `mse`: Calculates the score as the mean squared error</span>
<span class="sd">                of the teacher predictions and the student predictions.</span>
<span class="sd">                The MSE is calculated per test fold and aggregated across</span>
<span class="sd">                folds using the arithmetic mean.</span>
<span class="sd">                - `linear_predictor`: Calculates out of sample predictions</span>
<span class="sd">                for each test fold and caches them. Once out of sample</span>
<span class="sd">                predictions are produced for each sample, an appropriate</span>
<span class="sd">                survival loss between student predictions and the observed</span>
<span class="sd">                time and censoring indactor is calculated once, using only</span>
<span class="sd">                the cached out of sample predictions. See [1].</span>
<span class="sd">                - `basic`: Calculates the score as an appropriate survival</span>
<span class="sd">                loss between student predictions and observed time</span>
<span class="sd">                and event indicators in each test fold. The overall</span>
<span class="sd">                loss is obtained as an arithmetic mean across all folds.</span>
<span class="sd">                - `vvh`: Calculates the test score in each test fold as the difference</span>
<span class="sd">                between the score across all samples in that fold and only</span>
<span class="sd">                the training samples in that fold.The overall loss</span>
<span class="sd">                is obtained as an arithmetic mean across all folds. See [1, 2].</span>

<span class="sd">            `max_coef`:</span>
<span class="sd">                Places an upper bound on the number of non-zero coefficients</span>
<span class="sd">                the selected model returned after cross validation may have.</span>

<span class="sd">                In particular, if `max_coef=k`, during scoring, only models</span>
<span class="sd">                with a total number of non-zero coefficients less than k are</span>
<span class="sd">                considered.</span>

<span class="sd">                Currently, we still calculate the solutions for these</span>
<span class="sd">                models, we just disregard them at scoring time.</span>

<span class="sd">            `alpha_type`:</span>
<span class="sd">                Decides how the regularization hyperparameter is selected.</span>
<span class="sd">                For a given `cv_score_method` and `max_coef`, we end up with</span>
<span class="sd">                a vector of length k &gt; 1, that contains numeric scores,</span>
<span class="sd">                where lower is better (i.e., losses). `alpha_type` decides</span>
<span class="sd">                how we choose among the regularization hyperparameters corresponding</span>
<span class="sd">                to this loss vector.</span>

<span class="sd">                - `min`: Selects the regularization hyperparameter that</span>
<span class="sd">                yields the minimum loss.</span>

<span class="sd">                - `1se`: Selects the highest regularization hyperparameter</span>
<span class="sd">                that is within one standard error of the mean loss of the</span>
<span class="sd">                regularization hyperparameter with minimum loss [3].</span>

<span class="sd">                - `pcvl`: Selects a hyperparameter inbetween `min` and</span>
<span class="sd">                `1se` via a penalization term. See [4].</span>



<span class="sd">        References:</span>
<span class="sd">            [1] Dai, Biyue, and Patrick Breheny. &quot;Cross validation approaches for penalized Cox regression.&quot; arXiv preprint arXiv:1905.10432 (2019).</span>

<span class="sd">            [2] Verweij, Pierre JM, and Hans C. Van Houwelingen. &quot;Cross‐validation in survival analysis.&quot; Statistics in medicine 12.24 (1993): 2305-2314.</span>

<span class="sd">            [3] Hastie, Trevor, et al. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: Springer, 2009.</span>

<span class="sd">            [4] Ternès, Nils, Federico Rotolo, and Stefan Michiels. &quot;Empirical extensions of the lasso penalty to reduce the false discovery rate in high‐dimensional Cox regression models.&quot; Statistics in medicine 35.15 (2016): 2561-2573.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">l1_ratio</span><span class="o">=</span><span class="n">l1_ratio</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">n_alphas</span><span class="o">=</span><span class="n">n_alphas</span><span class="p">,</span>
            <span class="n">alphas</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">fit_intercept</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span>
            <span class="n">prune</span><span class="o">=</span><span class="n">prune</span><span class="p">,</span>
            <span class="n">positive</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv</span> <span class="o">=</span> <span class="n">cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stratify_cv</span> <span class="o">=</span> <span class="n">stratify_cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_cv</span> <span class="o">=</span> <span class="n">shuffle_cv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_score_method</span> <span class="o">=</span> <span class="n">cv_score_method</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_coef</span> <span class="o">=</span> <span class="n">max_coef</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_type</span> <span class="o">=</span> <span class="n">alpha_type</span></div>

<div class="viewcode-block" id="BaseKDSurv.fit"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.BaseKDSurv.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span>
        <span class="n">sample_weight</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Fit knowledge distilled semi-parametric survival model to given data.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Design matrix.</span>
<span class="sd">            y (npt.NDArray[np.float64]): Linear predictor as returned by the teacher.</span>
<span class="sd">            sample_weight (npt.NDArray[np.float64], optional): Sample weight used during model fitting.</span>
<span class="sd">                Currently unused and kept for sklearn compatibility. Defaults to None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_params</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_type</span> <span class="o">==</span> <span class="s2">&quot;1se&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_score_method</span> <span class="o">==</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;`alpha_type` `1se` is not available with `cv_score_method` `linear_predictor`.&quot;</span>
                    <span class="o">+</span> <span class="s2">&quot;Please choose another score method.&quot;</span>
                <span class="p">)</span>
        <span class="c1"># This makes sure that there is no duplication in memory.</span>
        <span class="c1"># Dealing right with copy_X is important in the following:</span>
        <span class="c1"># Multiple functions touch X and subsamples of X and can induce a</span>
        <span class="c1"># lot of duplication of memory</span>
        <span class="n">copy_X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">copy_X</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span>

        <span class="n">check_y_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">ensure_2d</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="n">time</span><span class="p">,</span> <span class="n">event</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">inverse_transform_survival_kd</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">sorted_ix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">time</span><span class="p">)</span>
        <span class="n">time</span> <span class="o">=</span> <span class="n">time</span><span class="p">[</span><span class="n">sorted_ix</span><span class="p">]</span>
        <span class="n">event</span> <span class="o">=</span> <span class="n">event</span><span class="p">[</span><span class="n">sorted_ix</span><span class="p">]</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">sorted_ix</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="c1"># Keep a reference to X</span>
            <span class="n">reference_to_old_X</span> <span class="o">=</span> <span class="n">X</span>
            <span class="c1"># Let us not impose fortran ordering so far: it is</span>
            <span class="c1"># not useful for the cross-validation loop and will be done</span>
            <span class="c1"># by the model fitting itself</span>

            <span class="c1"># Need to validate separately here.</span>
            <span class="c1"># We can&#39;t pass multi_output=True because that would allow y to be</span>
            <span class="c1"># csr. We also want to allow y to be 64 or 32 but check_X_y only</span>
            <span class="c1"># allows to convert for 64.</span>
            <span class="n">check_X_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csc&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">validate_separately</span><span class="o">=</span><span class="p">(</span><span class="n">check_X_params</span><span class="p">,</span> <span class="n">check_y_params</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">reference_to_old_X</span><span class="p">,</span> <span class="s2">&quot;data&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">may_share_memory</span><span class="p">(</span>
                    <span class="n">reference_to_old_X</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">data</span>
                <span class="p">):</span>
                    <span class="c1"># X is a sparse matrix and has been copied</span>
                    <span class="n">copy_X</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">elif</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">may_share_memory</span><span class="p">(</span><span class="n">reference_to_old_X</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
                <span class="c1"># X has been copied</span>
                <span class="n">copy_X</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">del</span> <span class="n">reference_to_old_X</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Need to validate separately here.</span>
            <span class="c1"># We can&#39;t pass multi_output=True because that would allow y to be</span>
            <span class="c1"># csr. We also want to allow y to be 64 or 32 but check_X_y only</span>
            <span class="c1"># allows to convert for 64.</span>
            <span class="n">check_X_params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csc&quot;</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
                <span class="n">order</span><span class="o">=</span><span class="s2">&quot;F&quot;</span><span class="p">,</span>
                <span class="n">copy</span><span class="o">=</span><span class="n">copy_X</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">validate_separately</span><span class="o">=</span><span class="p">(</span><span class="n">check_X_params</span><span class="p">,</span> <span class="n">check_y_params</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">copy_X</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">check_consistent_length</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_multitask</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;For multi-task outputs, use MultiTask</span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">column_or_1d</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">sparse</span><span class="o">.</span><span class="n">isspmatrix</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;X should be dense but a sparse matrix waspassed&quot;</span><span class="p">)</span>
            <span class="k">elif</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;For mono-task outputs, use </span><span class="si">%s</span><span class="s2">CV&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">[</span><span class="mi">9</span><span class="p">:]</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">numbers</span><span class="o">.</span><span class="n">Number</span><span class="p">):</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_estimator</span><span class="p">()</span>

        <span class="c1"># All LinearModelCV parameters except &#39;cv&#39; are acceptable</span>
        <span class="n">path_params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

        <span class="c1"># Pop `intercept` that is not parameter of the path function</span>
        <span class="n">path_params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;fit_intercept&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="s2">&quot;l1_ratio&quot;</span> <span class="ow">in</span> <span class="n">path_params</span><span class="p">:</span>
            <span class="n">l1_ratios</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">path_params</span><span class="p">[</span><span class="s2">&quot;l1_ratio&quot;</span><span class="p">])</span>
            <span class="c1"># For the first path, we need to set l1_ratio</span>
            <span class="n">path_params</span><span class="p">[</span><span class="s2">&quot;l1_ratio&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">l1_ratios</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">l1_ratios</span> <span class="o">=</span> <span class="p">[</span>
                <span class="mi">1</span><span class="p">,</span>
            <span class="p">]</span>
        <span class="n">path_params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cv&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">path_params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;n_jobs&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">alphas</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span>
        <span class="n">n_l1_ratio</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">l1_ratios</span><span class="p">)</span>

        <span class="n">check_scalar_alpha</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
            <span class="n">check_scalar</span><span class="p">,</span>
            <span class="n">target_type</span><span class="o">=</span><span class="n">Real</span><span class="p">,</span>
            <span class="n">min_val</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
            <span class="n">include_boundaries</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">alphas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">alphas</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">_alpha_grid</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="p">,</span>
                    <span class="n">l1_ratio</span><span class="o">=</span><span class="n">l1_ratio</span><span class="p">,</span>
                    <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                    <span class="n">eps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span>
                    <span class="n">n_alphas</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_alphas</span><span class="p">,</span>
                    <span class="n">copy_X</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy_X</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">for</span> <span class="n">l1_ratio</span> <span class="ow">in</span> <span class="n">l1_ratios</span>
            <span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Making sure alphas entries are scalars.</span>
            <span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">alpha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">alphas</span><span class="p">):</span>
                <span class="n">check_scalar_alpha</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;alphas[</span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
            <span class="c1"># Making sure alphas is properly ordered.</span>
            <span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">alphas</span><span class="p">)[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="n">n_l1_ratio</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="c1"># We want n_alphas to be the number of alphas used for each l1_ratio.</span>
        <span class="n">n_alphas</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">path_params</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;n_alphas&quot;</span><span class="p">:</span> <span class="n">n_alphas</span><span class="p">})</span>

        <span class="n">path_params</span><span class="p">[</span><span class="s2">&quot;copy_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">copy_X</span>
        <span class="c1"># We are not computing in parallel, we can modify X</span>
        <span class="c1"># inplace in the folds</span>
        <span class="k">if</span> <span class="n">effective_n_jobs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">path_params</span><span class="p">[</span><span class="s2">&quot;copy_X&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># init cross-validation generator</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">check_cv</span><span class="p">(</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">StratifiedKFold</span><span class="p">(</span>
                <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle_cv</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">stratify_cv</span>
            <span class="k">else</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">shuffle_cv</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">),</span>
            <span class="n">y</span><span class="o">=</span><span class="n">event</span><span class="p">,</span>
            <span class="n">classifier</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">stratify_cv</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Compute path for all folds and compute MSE to get the best alpha</span>
        <span class="n">folds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">event</span><span class="p">))</span>
        <span class="n">best_pl_score</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="c1"># We do a double for loop folded in one, in order to be able to</span>
        <span class="c1"># iterate in parallel on l1_ratio and folds</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">delayed</span><span class="p">(</span><span class="n">_path_predictions</span><span class="p">)(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">time</span><span class="p">,</span>
                <span class="n">event</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">train</span><span class="p">,</span>
                <span class="n">test</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">fit_intercept</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">path</span><span class="p">,</span>
                <span class="n">path_params</span><span class="p">,</span>
                <span class="n">alphas</span><span class="o">=</span><span class="n">this_alphas</span><span class="p">,</span>
                <span class="n">l1_ratio</span><span class="o">=</span><span class="n">this_l1_ratio</span><span class="p">,</span>
                <span class="n">X_order</span><span class="o">=</span><span class="s2">&quot;F&quot;</span><span class="p">,</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="o">.</span><span class="n">type</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">this_l1_ratio</span><span class="p">,</span> <span class="n">this_alphas</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">l1_ratios</span><span class="p">,</span> <span class="n">alphas</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">folds</span>
        <span class="p">)</span>
        <span class="n">predictions_paths</span> <span class="o">=</span> <span class="n">Parallel</span><span class="p">(</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">prefer</span><span class="o">=</span><span class="s2">&quot;threads&quot;</span><span class="p">,</span>
        <span class="p">)(</span><span class="n">jobs</span><span class="p">)</span>
        <span class="p">(</span>
            <span class="n">train_eta_folds</span><span class="p">,</span>
            <span class="n">test_eta_folds</span><span class="p">,</span>
            <span class="n">train_y_folds</span><span class="p">,</span>
            <span class="n">test_y_folds</span><span class="p">,</span>
            <span class="n">n_sparsity_folds</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="nb">zip</span><span class="p">(</span><span class="o">*</span><span class="n">predictions_paths</span><span class="p">)</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">test_eta_folds</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">l1_ratios</span><span class="p">))</span>

        <span class="n">mean_cv_score_l1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_cv_score</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_sd_score_l1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_sd_score</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_sparsity_l1</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mean_sparsity</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">l1_ratios</span><span class="p">)):</span>
            <span class="n">train_eta</span> <span class="o">=</span> <span class="n">train_eta_folds</span><span class="p">[</span><span class="n">n_folds</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="n">n_folds</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">test_eta</span> <span class="o">=</span> <span class="n">test_eta_folds</span><span class="p">[</span><span class="n">n_folds</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="n">n_folds</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">train_y</span> <span class="o">=</span> <span class="n">train_y_folds</span><span class="p">[</span><span class="n">n_folds</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="n">n_folds</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">test_y</span> <span class="o">=</span> <span class="n">test_y_folds</span><span class="p">[</span><span class="n">n_folds</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="n">n_folds</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">n_sparsity</span> <span class="o">=</span> <span class="n">n_sparsity_folds</span><span class="p">[</span><span class="n">n_folds</span> <span class="o">*</span> <span class="n">i</span> <span class="p">:</span> <span class="n">n_folds</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="n">n_sparsity</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">n_sparsity</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_score_method</span> <span class="o">==</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">:</span>
                <span class="n">train_eta_method</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">train_eta</span><span class="p">)</span>
                <span class="n">test_eta_method</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_eta</span><span class="p">)</span>
                <span class="n">train_y_method</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span>
                <span class="n">test_y_method</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span>

                <span class="p">(</span>
                    <span class="n">train_time</span><span class="p">,</span>
                    <span class="n">train_event</span><span class="p">,</span>
                    <span class="n">_</span><span class="p">,</span>
                <span class="p">)</span> <span class="o">=</span> <span class="n">inverse_transform_survival_kd</span><span class="p">(</span><span class="n">train_y_method</span><span class="p">)</span>
                <span class="p">(</span>
                    <span class="n">test_time</span><span class="p">,</span>
                    <span class="n">test_event</span><span class="p">,</span>
                    <span class="n">_</span><span class="p">,</span>
                <span class="p">)</span> <span class="o">=</span> <span class="n">inverse_transform_survival_kd</span><span class="p">(</span><span class="n">test_y_method</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                    <span class="n">likelihood</span> <span class="o">=</span> <span class="n">CVSCORERFACTORY</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_score_method</span><span class="p">](</span>
                        <span class="n">test_linear_predictor</span><span class="o">=</span><span class="n">test_eta_method</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                        <span class="n">test_time</span><span class="o">=</span><span class="n">test_time</span><span class="p">,</span>
                        <span class="n">test_event</span><span class="o">=</span><span class="n">test_event</span><span class="p">,</span>
                        <span class="n">score_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">mean_cv_score_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">likelihood</span><span class="p">)</span>
                    <span class="n">mean_sd_score_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
                    <span class="n">mean_sparsity_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_sparsity</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>

                <span class="n">mean_cv_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_cv_score_l1</span><span class="p">)</span>
                <span class="n">mean_sd_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_sd_score_l1</span><span class="p">)</span>
                <span class="n">mean_sparsity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_sparsity_l1</span><span class="p">)</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">test_fold_likelihoods</span> <span class="o">=</span> <span class="p">[]</span>

                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">alphas</span><span class="p">[</span><span class="n">i</span><span class="p">])):</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_folds</span><span class="p">):</span>
                        <span class="n">train_eta_method</span> <span class="o">=</span> <span class="n">train_eta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                        <span class="n">test_eta_method</span> <span class="o">=</span> <span class="n">test_eta</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
                        <span class="n">train_y_method</span> <span class="o">=</span> <span class="n">train_y</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                        <span class="n">test_y_method</span> <span class="o">=</span> <span class="n">test_y</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

                        <span class="p">(</span>
                            <span class="n">train_time</span><span class="p">,</span>
                            <span class="n">train_event</span><span class="p">,</span>
                            <span class="n">_</span><span class="p">,</span>
                        <span class="p">)</span> <span class="o">=</span> <span class="n">inverse_transform_survival_kd</span><span class="p">(</span><span class="n">train_y_method</span><span class="p">)</span>
                        <span class="p">(</span>
                            <span class="n">test_time</span><span class="p">,</span>
                            <span class="n">test_event</span><span class="p">,</span>
                            <span class="n">test_eta_hat</span><span class="p">,</span>
                        <span class="p">)</span> <span class="o">=</span> <span class="n">inverse_transform_survival_kd</span><span class="p">(</span><span class="n">test_y_method</span><span class="p">)</span>
                        <span class="n">fold_likelihood</span> <span class="o">=</span> <span class="n">CVSCORERFACTORY</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_score_method</span><span class="p">](</span>
                            <span class="n">test_linear_predictor</span><span class="o">=</span><span class="n">test_eta_method</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                            <span class="n">test_time</span><span class="o">=</span><span class="n">test_time</span><span class="p">,</span>
                            <span class="n">test_event</span><span class="o">=</span><span class="n">test_event</span><span class="p">,</span>
                            <span class="n">test_eta_hat</span><span class="o">=</span><span class="n">test_eta_hat</span><span class="p">,</span>
                            <span class="n">train_linear_predictor</span><span class="o">=</span><span class="n">train_eta_method</span><span class="p">[:,</span> <span class="p">:,</span> <span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                            <span class="n">train_time</span><span class="o">=</span><span class="n">train_time</span><span class="p">,</span>
                            <span class="n">train_event</span><span class="o">=</span><span class="n">train_event</span><span class="p">,</span>
                            <span class="n">score_function</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
                        <span class="p">)</span>
                        <span class="n">test_fold_likelihoods</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">fold_likelihood</span><span class="p">)</span>

                    <span class="n">mean_cv_score_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_fold_likelihoods</span><span class="p">))</span>
                    <span class="n">mean_sd_score_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_fold_likelihoods</span><span class="p">))</span>
                    <span class="n">mean_sparsity_l1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">n_sparsity</span><span class="p">[</span><span class="n">j</span><span class="p">])</span>
                <span class="n">mean_cv_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_cv_score_l1</span><span class="p">)</span>
                <span class="n">mean_sd_score</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_sd_score_l1</span><span class="p">)</span>
                <span class="n">mean_sparsity</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mean_sparsity_l1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pl_path_</span> <span class="o">=</span> <span class="n">mean_cv_score</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_type</span> <span class="o">==</span> <span class="s2">&quot;min&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">l1_alphas</span><span class="p">,</span> <span class="n">pl_alphas</span><span class="p">,</span> <span class="n">n_coefs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">l1_ratios</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">mean_cv_score</span><span class="p">,</span> <span class="n">mean_sparsity</span>
            <span class="p">):</span>
                <span class="n">i_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pl_alphas</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_coef</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="p">)</span>
                <span class="n">this_best_pl</span> <span class="o">=</span> <span class="n">pl_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">this_best_pl</span> <span class="o">&gt;</span> <span class="n">best_pl_score</span><span class="p">:</span>
                    <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">l1_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                    <span class="n">best_l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>
                    <span class="n">best_pl_score</span> <span class="o">=</span> <span class="n">this_best_pl</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_type</span> <span class="o">==</span> <span class="s2">&quot;1se&quot;</span><span class="p">:</span>
            <span class="n">n_best_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
            <span class="k">for</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">l1_alphas</span><span class="p">,</span> <span class="n">pl_alphas</span><span class="p">,</span> <span class="n">n_coefs</span><span class="p">,</span> <span class="n">sd_alphas</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">l1_ratios</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">mean_cv_score</span><span class="p">,</span> <span class="n">mean_sparsity</span><span class="p">,</span> <span class="n">mean_sd_score</span>
            <span class="p">):</span>
                <span class="n">i_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pl_alphas</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_coef</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="p">)</span>
                <span class="n">this_best_pl</span> <span class="o">=</span> <span class="n">pl_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">this_best_pl</span> <span class="o">&lt;</span> <span class="n">best_pl_score</span><span class="p">:</span>
                    <span class="n">best_pl_score</span> <span class="o">=</span> <span class="n">this_best_pl</span> <span class="o">-</span> <span class="p">(</span>
                        <span class="n">sd_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_folds</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="k">for</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">l1_alphas</span><span class="p">,</span> <span class="n">pl_alphas</span><span class="p">,</span> <span class="n">n_coefs</span><span class="p">,</span> <span class="n">sd_alphas</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">l1_ratios</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">mean_cv_score</span><span class="p">,</span> <span class="n">mean_sparsity</span><span class="p">,</span> <span class="n">mean_sd_score</span>
            <span class="p">):</span>
                <span class="n">i_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">))[</span>
                        <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                            <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_coef</span><span class="p">,</span>
                                <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pl_alphas</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">best_pl_score</span><span class="p">,</span>
                            <span class="p">)</span>
                        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="p">]</span>
                <span class="p">)</span>
                <span class="n">n_coef</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">n_coef</span> <span class="o">&lt;</span> <span class="n">n_best_coef</span><span class="p">:</span>
                    <span class="n">n_best_coef</span> <span class="o">=</span> <span class="n">n_coef</span>
                    <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">l1_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                    <span class="n">best_l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>

        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha_type</span> <span class="o">==</span> <span class="s2">&quot;pcvl&quot;</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">l1_ratio</span><span class="p">,</span> <span class="n">l1_alphas</span><span class="p">,</span> <span class="n">pl_alphas</span><span class="p">,</span> <span class="n">n_coefs</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span>
                <span class="n">l1_ratios</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">mean_cv_score</span><span class="p">,</span> <span class="n">mean_sparsity</span>
            <span class="p">):</span>
                <span class="n">pl_alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pl_alphas</span><span class="p">)</span>
                <span class="n">n_coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)</span>
                <span class="n">i_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pl_alphas</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_coef</span><span class="p">)[</span><span class="mi">0</span><span class="p">]]</span>
                <span class="p">)</span>
                <span class="n">sparsity_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">n_coefs</span><span class="p">)[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                <span class="n">pl_best_alpha</span> <span class="o">=</span> <span class="n">pl_alphas</span><span class="p">[</span><span class="n">i_best_alpha</span><span class="p">]</span>
                <span class="n">pl_alpha_max</span> <span class="o">=</span> <span class="n">pl_alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">transformed_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">i_best_alpha</span><span class="p">)</span>
                <span class="n">transformed_pl_alphas</span> <span class="o">=</span> <span class="n">pl_alphas</span><span class="p">[</span><span class="n">transformed_range</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span>
                    <span class="p">((</span><span class="n">pl_best_alpha</span> <span class="o">-</span> <span class="n">pl_alpha_max</span><span class="p">)</span> <span class="o">/</span> <span class="n">sparsity_best_alpha</span><span class="p">)</span>
                    <span class="o">*</span> <span class="n">n_coefs</span><span class="p">[</span><span class="n">transformed_range</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">transformed_i_best_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">transformed_pl_alphas</span><span class="p">)</span>
                <span class="n">this_best_pl_transformed</span> <span class="o">=</span> <span class="n">transformed_pl_alphas</span><span class="p">[</span>
                    <span class="n">transformed_i_best_alpha</span>
                <span class="p">]</span>
                <span class="k">if</span> <span class="n">this_best_pl_transformed</span> <span class="o">&gt;</span> <span class="n">best_pl_score</span><span class="p">:</span>
                    <span class="n">best_alpha</span> <span class="o">=</span> <span class="n">l1_alphas</span><span class="p">[</span><span class="n">transformed_i_best_alpha</span><span class="p">]</span>
                    <span class="n">best_l1_ratio</span> <span class="o">=</span> <span class="n">l1_ratio</span>
                    <span class="n">best_pl_score</span> <span class="o">=</span> <span class="n">this_best_pl_transformed</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio_</span> <span class="o">=</span> <span class="n">best_l1_ratio</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha_</span> <span class="o">=</span> <span class="n">best_alpha</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">alphas</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">n_l1_ratio</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># Remove duplicate alphas in case alphas is provided.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alphas_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">alphas</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="c1"># Refit the model with the parameters selected</span>
        <span class="n">common_params</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">name</span><span class="p">:</span> <span class="n">value</span>
            <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="n">model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">common_params</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">best_alpha</span>
        <span class="n">model</span><span class="o">.</span><span class="n">l1_ratio</span> <span class="o">=</span> <span class="n">best_l1_ratio</span>
        <span class="n">model</span><span class="o">.</span><span class="n">copy_X</span> <span class="o">=</span> <span class="n">copy_X</span>
        <span class="n">precompute</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;precompute&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">precompute</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">precompute</span> <span class="o">==</span> <span class="s2">&quot;auto&quot;</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">precompute</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># MultiTaskElasticNetCV does not (yet) support sample_weight, even</span>
            <span class="c1"># not sample_weight=None.</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;l1_ratio&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1_ratio_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">coef_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">intercept_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">intercept_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dual_gap_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">dual_gap_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">n_iter_</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train_time_</span> <span class="o">=</span> <span class="n">time</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_event_</span> <span class="o">=</span> <span class="n">event</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_eta_</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span></div>

<div class="viewcode-block" id="BaseKDSurv._is_multitask"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.BaseKDSurv._is_multitask">[docs]</a>    <span class="k">def</span> <span class="nf">_is_multitask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Return whether the model instance in question is a multitask model.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">False</span></div>

<div class="viewcode-block" id="BaseKDSurv.predict"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.BaseKDSurv.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Calculate linear predictor corresponding to query design matrix X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Query design matrix.</span>

<span class="sd">        Returns:</span>
<span class="sd">            npt.NDArray[np.float64]: Linear predictor of the samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span></div></div>


<div class="viewcode-block" id="KDPHElasticNetCV"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDPHElasticNetCV">[docs]</a><span class="k">class</span> <span class="nc">KDPHElasticNetCV</span><span class="p">(</span><span class="n">BaseKDSurv</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Child-class of BaseKDSurv to perform knowledge distillation specifically for Cox PH models.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="KDPHElasticNetCV.__init__"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDPHElasticNetCV.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tie_correction</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;efron&quot;</span><span class="p">,</span>
        <span class="n">l1_ratio</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">n_alphas</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="n">p0</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">prune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stratify_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">shuffle_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cv_score_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">,</span>
        <span class="n">max_coef</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">alpha_type</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Args:</span>
<span class="sd">            tie_correction (str): Which method to use to correct for ties</span>
<span class="sd">            in observed survival times. Must be one of &quot;breslow&quot; or &quot;efron&quot;.</span>
<span class="sd">            l1_ratio (Union[float, List[float]], optional): Float between 0 and 1 passed</span>
<span class="sd">                to ElasticNet (scaling between l1 and l2 penalties). For ``l1_ratio = 0``</span>
<span class="sd">                the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.</span>
<span class="sd">                For ``0 &lt; l1_ratio &lt; 1``, the penalty is a combination of L1 and L2.</span>
<span class="sd">                This parameter can be a list, in which case the different values are tested</span>
<span class="sd">                by cross-validation and the one giving the best prediction score is used.</span>
<span class="sd">                Note that a good choice of list of values for l1_ratio is often to put more</span>
<span class="sd">                values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge),</span>
<span class="sd">                as in ``[.1, .5, .7, .9, .95, .99, 1]``. Defaults to 1.0.</span>
<span class="sd">            eps (float, optional): Length of the path. ``eps=1e-3`` means that</span>
<span class="sd">                ``alpha_min / alpha_max = 1e-3``. Defaults to 1e-3.</span>
<span class="sd">            n_alphas (int, optional): Number of alphas along the regularization path,</span>
<span class="sd">                used for each l1_ratio. Defaults to 100.</span>
<span class="sd">            max_iter (int, optional): The maximum number of iterations. Defaults to 100.</span>
<span class="sd">            tol (float, optional): The tolerance for the optimization: if the updates are</span>
<span class="sd">                smaller than ``tol``, the optimization code checks the dual gap for optimality</span>
<span class="sd">                and continues until it is smaller than ``tol``. Defaults to 1e-4.</span>
<span class="sd">            cv (int, optional): Number of folds to perform to select hyperparameters.</span>
<span class="sd">                Defaults to 5. See also `stratify_cv`.</span>
<span class="sd">            verbose (int, optional): Degree of verbosity. Defaults to 0.</span>
<span class="sd">            max_epochs (int, optional): Maximum number of coordinate descent epochs when</span>
<span class="sd">                solving a subproblem. Defaults to 50000.</span>
<span class="sd">            p0 (int, optional): Number of features in the first working set. Defaults to 10.</span>
<span class="sd">            prune (bool, optional): Whether to use pruning when growing the working sets.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            n_jobs (Optional[int], optional): Number of CPUs to use during the cross validation.</span>
<span class="sd">                ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">                ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">                for more details. Defaults to None.</span>
<span class="sd">            stratify_cv (bool, optional): Whether to perform the cross-validation stratified</span>
<span class="sd">                on the event indicator or not. Defaults to True.</span>
<span class="sd">            seed (Optional[int], optional): Random seed. Defaults to 42.</span>
<span class="sd">            shuffle_cv (bool, optional): Whether to perform shuffling to generate</span>
<span class="sd">                CV fold indices. Defaults to False.</span>
<span class="sd">            cv_score_method (str, optional): Which scoring method to use. Defaults to &quot;linear_predictor&quot;.</span>
<span class="sd">                Must be one of &quot;linear_predictor&quot;, &quot;mse&quot;, &quot;basic&quot; and &quot;vvh&quot;.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            max_coef (float, optional): Maximum number of non-zero covariates to be selected</span>
<span class="sd">                with chosen optimal regularization hyperparameter. Defaults to np.inf.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            alpha_type (str, optional): How to select the optimal regularization hyperparameter. Defaults to &quot;min&quot;.</span>
<span class="sd">                Must be one of &quot;min&quot;, &quot;1se&quot; and &quot;pcvl&quot;. See Notes.</span>



<span class="sd">        Notes:</span>
<span class="sd">            `cv_score_method`:</span>
<span class="sd">                Decides how the score which is used to select the optimal</span>
<span class="sd">                regularization hyperparameter is selected. The `basic`</span>
<span class="sd">                approach may suffer from issues with small event sizes or</span>
<span class="sd">                for large number of folds [1]. Meanwhile, the `mse` approach</span>
<span class="sd">                may yield good teacher-student fidelity, but suboptimal</span>
<span class="sd">                survival predictions.</span>

<span class="sd">                - `mse`: Calculates the score as the mean squared error</span>
<span class="sd">                of the teacher predictions and the student predictions.</span>
<span class="sd">                The MSE is calculated per test fold and aggregated across</span>
<span class="sd">                folds using the arithmetic mean.</span>
<span class="sd">                - `linear_predictor`: Calculates out of sample predictions</span>
<span class="sd">                for each test fold and caches them. Once out of sample</span>
<span class="sd">                predictions are produced for each sample, an appropriate</span>
<span class="sd">                survival loss between student predictions and the observed</span>
<span class="sd">                time and censoring indactor is calculated once, using only</span>
<span class="sd">                the cached out of sample predictions. See [1].</span>
<span class="sd">                - `basic`: Calculates the score as an appropriate survival</span>
<span class="sd">                loss between student predictions and observed time</span>
<span class="sd">                and event indicators in each test fold. The overall</span>
<span class="sd">                loss is obtained as an arithmetic mean across all folds.</span>
<span class="sd">                - `vvh`: Calculates the test score in each test fold as the difference</span>
<span class="sd">                between the score across all samples in that fold and only</span>
<span class="sd">                the training samples in that fold.The overall loss</span>
<span class="sd">                is obtained as an arithmetic mean across all folds. See [1, 2].</span>

<span class="sd">            `max_coef`:</span>
<span class="sd">                Places an upper bound on the number of non-zero coefficients</span>
<span class="sd">                the selected model returned after cross validation may have.</span>

<span class="sd">                In particular, if `max_coef=k`, during scoring, only models</span>
<span class="sd">                with a total number of non-zero coefficients less than k are</span>
<span class="sd">                considered.</span>

<span class="sd">                Currently, we still calculate the solutions for these</span>
<span class="sd">                models, we just disregard them at scoring time.</span>

<span class="sd">            `alpha_type`:</span>
<span class="sd">                Decides how the regularization hyperparameter is selected.</span>
<span class="sd">                For a given `cv_score_method` and `max_coef`, we end up with</span>
<span class="sd">                a vector of length k &gt; 1, that contains numeric scores,</span>
<span class="sd">                where lower is better (i.e., losses). `alpha_type` decides</span>
<span class="sd">                how we choose among the regularization hyperparameters corresponding</span>
<span class="sd">                to this loss vector.</span>

<span class="sd">                - `min`: Selects the regularization hyperparameter that</span>
<span class="sd">                yields the minimum loss.</span>

<span class="sd">                - `1se`: Selects the highest regularization hyperparameter</span>
<span class="sd">                that is within one standard error of the mean loss of the</span>
<span class="sd">                regularization hyperparameter with minimum loss [3].</span>

<span class="sd">                - `pcvl`: Selects a hyperparameter inbetween `min` and</span>
<span class="sd">                `1se` via a penalization term. See [4].</span>



<span class="sd">        References:</span>
<span class="sd">            [1] Dai, Biyue, and Patrick Breheny. &quot;Cross validation approaches for penalized Cox regression.&quot; arXiv preprint arXiv:1905.10432 (2019).</span>

<span class="sd">            [2] Verweij, Pierre JM, and Hans C. Van Houwelingen. &quot;Cross‐validation in survival analysis.&quot; Statistics in medicine 12.24 (1993): 2305-2314.</span>

<span class="sd">            [3] Hastie, Trevor, et al. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: Springer, 2009.</span>

<span class="sd">            [4] Ternès, Nils, Federico Rotolo, and Stefan Michiels. &quot;Empirical extensions of the lasso penalty to reduce the false discovery rate in high‐dimensional Cox regression models.&quot; Statistics in medicine 35.15 (2016): 2561-2573.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">l1_ratio</span><span class="o">=</span><span class="n">l1_ratio</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">n_alphas</span><span class="o">=</span><span class="n">n_alphas</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span>
            <span class="n">prune</span><span class="o">=</span><span class="n">prune</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">stratify_cv</span><span class="o">=</span><span class="n">stratify_cv</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">shuffle_cv</span><span class="o">=</span><span class="n">shuffle_cv</span><span class="p">,</span>
            <span class="n">cv_score_method</span><span class="o">=</span><span class="n">cv_score_method</span><span class="p">,</span>
            <span class="n">max_coef</span><span class="o">=</span><span class="n">max_coef</span><span class="p">,</span>
            <span class="n">alpha_type</span><span class="o">=</span><span class="n">alpha_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">tie_correction</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;breslow&quot;</span><span class="p">,</span> <span class="s2">&quot;efron&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Expected `tie_corection` to be in [&#39;breslow&#39;, &#39;efron&#39;].&quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;Found </span><span class="si">{</span><span class="n">tie_correction</span><span class="si">}</span><span class="s2"> instead.&quot;</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tie_correction</span> <span class="o">=</span> <span class="n">tie_correction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">LOSS_FACTORY</span><span class="p">[</span><span class="n">tie_correction</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span> <span class="o">=</span> <span class="n">BASELINE_HAZARD_FACTORY</span><span class="p">[</span><span class="s2">&quot;breslow&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="KDPHElasticNetCV.predict_cumulative_hazard_function"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDPHElasticNetCV.predict_cumulative_hazard_function">[docs]</a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">time</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Predict cumulative hazard function for patients in `X` at times `time`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Query design matrix with u rows and p columns.</span>
<span class="sd">            time (npt.NDArray[np.float64]): Query times of dimension k. Assumed to be unique and ordered.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: Raises ValueError when the event times are not unique and sorted in ascending order.</span>

<span class="sd">        Returns:</span>
<span class="sd">            npt.NDArray[np.float64]: Query cumulative hazard function for samples 1, ..., u</span>
<span class="sd">                and times 1, ..., k. Thus, has u rows and k columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Times for survival and cumulative hazard prediction must be greater than or equal to zero.&quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;Minimum time found was </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="o">+</span> <span class="s2">&quot;Please remove any times strictly less than zero.&quot;</span>
            <span class="p">)</span>
        <span class="n">cumulative_baseline_hazards_times</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span>
        <span class="n">cumulative_baseline_hazards</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span>
        <span class="p">(</span>
            <span class="n">cumulative_baseline_hazards_times</span><span class="p">,</span>
            <span class="n">cumulative_baseline_hazards</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span><span class="p">(</span>
            <span class="n">time</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_time_</span><span class="p">,</span> <span class="n">event</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_event_</span><span class="p">,</span> <span class="n">eta</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eta_</span>
        <span class="p">)</span>
        <span class="n">cumulative_baseline_hazards</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">cumulative_baseline_hazards</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">cumulative_baseline_hazards_times</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
            <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.0</span><span class="p">]),</span> <span class="n">cumulative_baseline_hazards_times</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">cumulative_baseline_hazards</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
            <span class="n">A</span><span class="o">=</span><span class="n">cumulative_baseline_hazards</span><span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">digitize</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">time</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">cumulative_baseline_hazards_times</span><span class="p">,</span> <span class="n">right</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="o">-</span> <span class="mi">1</span>
            <span class="p">],</span>
            <span class="n">reps</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">time</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">log_hazards</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">tile</span><span class="p">(</span>
                <span class="n">A</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
                <span class="n">reps</span><span class="o">=</span><span class="n">time</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">time</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            <span class="o">.</span><span class="n">T</span>
        <span class="p">)</span>
        <span class="n">cumulative_hazard_function</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="n">cumulative_baseline_hazards</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">log_hazards</span><span class="p">),</span>
            <span class="n">columns</span><span class="o">=</span><span class="n">time</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">cumulative_hazard_function</span></div></div>


<div class="viewcode-block" id="KDAFTElasticNetCV"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDAFTElasticNetCV">[docs]</a><span class="k">class</span> <span class="nc">KDAFTElasticNetCV</span><span class="p">(</span><span class="n">BaseKDSurv</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Child-class of BaseKDSurv to perform knowledge distillation specifically for semiparametric AFT models.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="KDAFTElasticNetCV.__init__"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDAFTElasticNetCV.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bandwidth</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">l1_ratio</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">n_alphas</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="n">p0</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">prune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stratify_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">shuffle_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cv_score_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">,</span>
        <span class="n">max_coef</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">alpha_type</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Args:</span>
<span class="sd">            bandwidth (Optional[float]): Bandwidth to use for kernel-smoothing</span>
<span class="sd">                the profile likelihood. If not provided, a theoretically</span>
<span class="sd">                motivated profile likelihood is estimated based on the data.</span>
<span class="sd">            in observed survival times. Must be one of &quot;breslow&quot; or &quot;efron&quot;.</span>
<span class="sd">            l1_ratio (Union[float, List[float]], optional): Float between 0 and 1 passed</span>
<span class="sd">                to ElasticNet (scaling between l1 and l2 penalties). For ``l1_ratio = 0``</span>
<span class="sd">                the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.</span>
<span class="sd">                For ``0 &lt; l1_ratio &lt; 1``, the penalty is a combination of L1 and L2.</span>
<span class="sd">                This parameter can be a list, in which case the different values are tested</span>
<span class="sd">                by cross-validation and the one giving the best prediction score is used.</span>
<span class="sd">                Note that a good choice of list of values for l1_ratio is often to put more</span>
<span class="sd">                values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge),</span>
<span class="sd">                as in ``[.1, .5, .7, .9, .95, .99, 1]``. Defaults to 1.0.</span>
<span class="sd">            eps (float, optional): Length of the path. ``eps=1e-3`` means that</span>
<span class="sd">                ``alpha_min / alpha_max = 1e-3``. Defaults to 1e-3.</span>
<span class="sd">            n_alphas (int, optional): Number of alphas along the regularization path,</span>
<span class="sd">                used for each l1_ratio. Defaults to 100.</span>
<span class="sd">            max_iter (int, optional): The maximum number of iterations. Defaults to 100.</span>
<span class="sd">            tol (float, optional): The tolerance for the optimization: if the updates are</span>
<span class="sd">                smaller than ``tol``, the optimization code checks the dual gap for optimality</span>
<span class="sd">                and continues until it is smaller than ``tol``. Defaults to 1e-4.</span>
<span class="sd">            cv (int, optional): Number of folds to perform to select hyperparameters.</span>
<span class="sd">                Defaults to 5. See also `stratify_cv`.</span>
<span class="sd">            verbose (int, optional): Degree of verbosity. Defaults to 0.</span>
<span class="sd">            max_epochs (int, optional): Maximum number of coordinate descent epochs when</span>
<span class="sd">                solving a subproblem. Defaults to 50000.</span>
<span class="sd">            p0 (int, optional): Number of features in the first working set. Defaults to 10.</span>
<span class="sd">            prune (bool, optional): Whether to use pruning when growing the working sets.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            n_jobs (Optional[int], optional): Number of CPUs to use during the cross validation.</span>
<span class="sd">                ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">                ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">                for more details. Defaults to None.</span>
<span class="sd">            stratify_cv (bool, optional): Whether to perform the cross-validation stratified</span>
<span class="sd">                on the event indicator or not. Defaults to True.</span>
<span class="sd">            seed (Optional[int], optional): Random seed. Defaults to 42.</span>
<span class="sd">            shuffle_cv (bool, optional): Whether to perform shuffling to generate</span>
<span class="sd">                CV fold indices. Defaults to False.</span>
<span class="sd">            cv_score_method (str, optional): Which scoring method to use. Defaults to &quot;linear_predictor&quot;.</span>
<span class="sd">                Must be one of &quot;linear_predictor&quot;, &quot;mse&quot;, &quot;basic&quot; and &quot;vvh&quot;.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            max_coef (float, optional): Maximum number of non-zero covariates to be selected</span>
<span class="sd">                with chosen optimal regularization hyperparameter. Defaults to np.inf.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            alpha_type (str, optional): How to select the optimal regularization hyperparameter. Defaults to &quot;min&quot;.</span>
<span class="sd">                Must be one of &quot;min&quot;, &quot;1se&quot; and &quot;pcvl&quot;. See Notes.</span>



<span class="sd">        Notes:</span>
<span class="sd">            `cv_score_method`:</span>
<span class="sd">                Decides how the score which is used to select the optimal</span>
<span class="sd">                regularization hyperparameter is selected. The `basic`</span>
<span class="sd">                approach may suffer from issues with small event sizes or</span>
<span class="sd">                for large number of folds [1]. Meanwhile, the `mse` approach</span>
<span class="sd">                may yield good teacher-student fidelity, but suboptimal</span>
<span class="sd">                survival predictions.</span>

<span class="sd">                - `mse`: Calculates the score as the mean squared error</span>
<span class="sd">                of the teacher predictions and the student predictions.</span>
<span class="sd">                The MSE is calculated per test fold and aggregated across</span>
<span class="sd">                folds using the arithmetic mean.</span>
<span class="sd">                - `linear_predictor`: Calculates out of sample predictions</span>
<span class="sd">                for each test fold and caches them. Once out of sample</span>
<span class="sd">                predictions are produced for each sample, an appropriate</span>
<span class="sd">                survival loss between student predictions and the observed</span>
<span class="sd">                time and censoring indactor is calculated once, using only</span>
<span class="sd">                the cached out of sample predictions. See [1].</span>
<span class="sd">                - `basic`: Calculates the score as an appropriate survival</span>
<span class="sd">                loss between student predictions and observed time</span>
<span class="sd">                and event indicators in each test fold. The overall</span>
<span class="sd">                loss is obtained as an arithmetic mean across all folds.</span>
<span class="sd">                - `vvh`: Calculates the test score in each test fold as the difference</span>
<span class="sd">                between the score across all samples in that fold and only</span>
<span class="sd">                the training samples in that fold.The overall loss</span>
<span class="sd">                is obtained as an arithmetic mean across all folds. See [1, 2].</span>

<span class="sd">            `max_coef`:</span>
<span class="sd">                Places an upper bound on the number of non-zero coefficients</span>
<span class="sd">                the selected model returned after cross validation may have.</span>

<span class="sd">                In particular, if `max_coef=k`, during scoring, only models</span>
<span class="sd">                with a total number of non-zero coefficients less than k are</span>
<span class="sd">                considered.</span>

<span class="sd">                Currently, we still calculate the solutions for these</span>
<span class="sd">                models, we just disregard them at scoring time.</span>

<span class="sd">            `alpha_type`:</span>
<span class="sd">                Decides how the regularization hyperparameter is selected.</span>
<span class="sd">                For a given `cv_score_method` and `max_coef`, we end up with</span>
<span class="sd">                a vector of length k &gt; 1, that contains numeric scores,</span>
<span class="sd">                where lower is better (i.e., losses). `alpha_type` decides</span>
<span class="sd">                how we choose among the regularization hyperparameters corresponding</span>
<span class="sd">                to this loss vector.</span>

<span class="sd">                - `min`: Selects the regularization hyperparameter that</span>
<span class="sd">                yields the minimum loss.</span>

<span class="sd">                - `1se`: Selects the highest regularization hyperparameter</span>
<span class="sd">                that is within one standard error of the mean loss of the</span>
<span class="sd">                regularization hyperparameter with minimum loss [3].</span>

<span class="sd">                - `pcvl`: Selects a hyperparameter inbetween `min` and</span>
<span class="sd">                `1se` via a penalization term. See [4].</span>



<span class="sd">        References:</span>
<span class="sd">            [1] Dai, Biyue, and Patrick Breheny. &quot;Cross validation approaches for penalized Cox regression.&quot; arXiv preprint arXiv:1905.10432 (2019).</span>

<span class="sd">            [2] Verweij, Pierre JM, and Hans C. Van Houwelingen. &quot;Cross‐validation in survival analysis.&quot; Statistics in medicine 12.24 (1993): 2305-2314.</span>

<span class="sd">            [3] Hastie, Trevor, et al. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: Springer, 2009.</span>

<span class="sd">            [4] Ternès, Nils, Federico Rotolo, and Stefan Michiels. &quot;Empirical extensions of the lasso penalty to reduce the false discovery rate in high‐dimensional Cox regression models.&quot; Statistics in medicine 35.15 (2016): 2561-2573.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">l1_ratio</span><span class="o">=</span><span class="n">l1_ratio</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">n_alphas</span><span class="o">=</span><span class="n">n_alphas</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span>
            <span class="n">prune</span><span class="o">=</span><span class="n">prune</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">stratify_cv</span><span class="o">=</span><span class="n">stratify_cv</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">shuffle_cv</span><span class="o">=</span><span class="n">shuffle_cv</span><span class="p">,</span>
            <span class="n">cv_score_method</span><span class="o">=</span><span class="n">cv_score_method</span><span class="p">,</span>
            <span class="n">max_coef</span><span class="o">=</span><span class="n">max_coef</span><span class="p">,</span>
            <span class="n">alpha_type</span><span class="o">=</span><span class="n">alpha_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bandwidth</span> <span class="o">=</span> <span class="n">bandwidth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">LOSS_FACTORY</span><span class="p">[</span><span class="s2">&quot;aft&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span> <span class="o">=</span> <span class="n">BASELINE_HAZARD_FACTORY</span><span class="p">[</span><span class="s2">&quot;aft&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="KDAFTElasticNetCV.predict_cumulative_hazard_function"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDAFTElasticNetCV.predict_cumulative_hazard_function">[docs]</a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">time</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Predict cumulative hazard function for patients in `X` at times `time`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Query design matrix with u rows and p columns.</span>
<span class="sd">            time (npt.NDArray[np.float64]): Query times of dimension k. Assumed to be unique and ordered.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: Raises ValueError when the event times are not unique and sorted in ascending order.</span>

<span class="sd">        Returns:</span>
<span class="sd">            npt.NDArray[np.float64]: Query cumulative hazard function for samples 1, ..., u</span>
<span class="sd">                and times 1, ..., k. Thus, has u rows and k columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Times for survival and cumulative hazard prediction must be greater than or equal to zero.&quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;Minimum time found was </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="o">+</span> <span class="s2">&quot;Please remove any times strictly less than zero.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span><span class="p">(</span>
            <span class="n">time_query</span><span class="o">=</span><span class="n">time</span><span class="p">,</span>
            <span class="n">eta_query</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">),</span>
            <span class="n">time_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_time_</span><span class="p">,</span>
            <span class="n">event_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_event_</span><span class="p">,</span>
            <span class="n">eta_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eta_</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="KDEHMultiTaskLassoCV"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV">[docs]</a><span class="k">class</span> <span class="nc">KDEHMultiTaskLassoCV</span><span class="p">(</span><span class="n">BaseKDSurv</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Child-class of BaseKDSurv to perform knowledge distillation specifically for semiparametric EH models.&quot;&quot;&quot;</span>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV.__init__"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV.__init__">[docs]</a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">bandwidth</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">n_alphas</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
        <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">cv</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
        <span class="n">p0</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
        <span class="n">prune</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stratify_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">shuffle_cv</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cv_score_method</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;linear_predictor&quot;</span><span class="p">,</span>
        <span class="n">max_coef</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span>
        <span class="n">alpha_type</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Constructor.</span>

<span class="sd">        Args:</span>
<span class="sd">            bandwidth (Optional[float]): Bandwidth to use for kernel-smoothing</span>
<span class="sd">                the profile likelihood. If not provided, a theoretically</span>
<span class="sd">                motivated profile likelihood is estimated based on the data.</span>
<span class="sd">            in observed survival times. Must be one of &quot;breslow&quot; or &quot;efron&quot;.</span>
<span class="sd">            l1_ratio (Union[float, List[float]], optional): Float between 0 and 1 passed</span>
<span class="sd">                to ElasticNet (scaling between l1 and l2 penalties). For ``l1_ratio = 0``</span>
<span class="sd">                the penalty is an L2 penalty. For ``l1_ratio = 1`` it is an L1 penalty.</span>
<span class="sd">                For ``0 &lt; l1_ratio &lt; 1``, the penalty is a combination of L1 and L2.</span>
<span class="sd">                This parameter can be a list, in which case the different values are tested</span>
<span class="sd">                by cross-validation and the one giving the best prediction score is used.</span>
<span class="sd">                Note that a good choice of list of values for l1_ratio is often to put more</span>
<span class="sd">                values close to 1 (i.e. Lasso) and less close to 0 (i.e. Ridge),</span>
<span class="sd">                as in ``[.1, .5, .7, .9, .95, .99, 1]``. Defaults to 1.0.</span>
<span class="sd">            eps (float, optional): Length of the path. ``eps=1e-3`` means that</span>
<span class="sd">                ``alpha_min / alpha_max = 1e-3``. Defaults to 1e-3.</span>
<span class="sd">            n_alphas (int, optional): Number of alphas along the regularization path,</span>
<span class="sd">                used for each l1_ratio. Defaults to 100.</span>
<span class="sd">            max_iter (int, optional): The maximum number of iterations. Defaults to 100.</span>
<span class="sd">            tol (float, optional): The tolerance for the optimization: if the updates are</span>
<span class="sd">                smaller than ``tol``, the optimization code checks the dual gap for optimality</span>
<span class="sd">                and continues until it is smaller than ``tol``. Defaults to 1e-4.</span>
<span class="sd">            cv (int, optional): Number of folds to perform to select hyperparameters.</span>
<span class="sd">                Defaults to 5. See also `stratify_cv`.</span>
<span class="sd">            verbose (int, optional): Degree of verbosity. Defaults to 0.</span>
<span class="sd">            max_epochs (int, optional): Maximum number of coordinate descent epochs when</span>
<span class="sd">                solving a subproblem. Defaults to 50000.</span>
<span class="sd">            p0 (int, optional): Number of features in the first working set. Defaults to 10.</span>
<span class="sd">            prune (bool, optional): Whether to use pruning when growing the working sets.</span>
<span class="sd">                Defaults to True.</span>
<span class="sd">            n_jobs (Optional[int], optional): Number of CPUs to use during the cross validation.</span>
<span class="sd">                ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.</span>
<span class="sd">                ``-1`` means using all processors. See :term:`Glossary &lt;n_jobs&gt;`</span>
<span class="sd">                for more details. Defaults to None.</span>
<span class="sd">            stratify_cv (bool, optional): Whether to perform the cross-validation stratified</span>
<span class="sd">                on the event indicator or not. Defaults to True.</span>
<span class="sd">            seed (Optional[int], optional): Random seed. Defaults to 42.</span>
<span class="sd">            shuffle_cv (bool, optional): Whether to perform shuffling to generate</span>
<span class="sd">                CV fold indices. Defaults to False.</span>
<span class="sd">            cv_score_method (str, optional): Which scoring method to use. Defaults to &quot;linear_predictor&quot;.</span>
<span class="sd">                Must be one of &quot;linear_predictor&quot;, &quot;mse&quot;, &quot;basic&quot; and &quot;vvh&quot;.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            max_coef (float, optional): Maximum number of non-zero covariates to be selected</span>
<span class="sd">                with chosen optimal regularization hyperparameter. Defaults to np.inf.</span>
<span class="sd">                See Notes.</span>
<span class="sd">            alpha_type (str, optional): How to select the optimal regularization hyperparameter. Defaults to &quot;min&quot;.</span>
<span class="sd">                Must be one of &quot;min&quot;, &quot;1se&quot; and &quot;pcvl&quot;. See Notes.</span>



<span class="sd">        Notes:</span>
<span class="sd">            `cv_score_method`:</span>
<span class="sd">                Decides how the score which is used to select the optimal</span>
<span class="sd">                regularization hyperparameter is selected. The `basic`</span>
<span class="sd">                approach may suffer from issues with small event sizes or</span>
<span class="sd">                for large number of folds [1]. Meanwhile, the `mse` approach</span>
<span class="sd">                may yield good teacher-student fidelity, but suboptimal</span>
<span class="sd">                survival predictions.</span>

<span class="sd">                - `mse`: Calculates the score as the mean squared error</span>
<span class="sd">                of the teacher predictions and the student predictions.</span>
<span class="sd">                The MSE is calculated per test fold and aggregated across</span>
<span class="sd">                folds using the arithmetic mean.</span>
<span class="sd">                - `linear_predictor`: Calculates out of sample predictions</span>
<span class="sd">                for each test fold and caches them. Once out of sample</span>
<span class="sd">                predictions are produced for each sample, an appropriate</span>
<span class="sd">                survival loss between student predictions and the observed</span>
<span class="sd">                time and censoring indactor is calculated once, using only</span>
<span class="sd">                the cached out of sample predictions. See [1].</span>
<span class="sd">                - `basic`: Calculates the score as an appropriate survival</span>
<span class="sd">                loss between student predictions and observed time</span>
<span class="sd">                and event indicators in each test fold. The overall</span>
<span class="sd">                loss is obtained as an arithmetic mean across all folds.</span>
<span class="sd">                - `vvh`: Calculates the test score in each test fold as the difference</span>
<span class="sd">                between the score across all samples in that fold and only</span>
<span class="sd">                the training samples in that fold.The overall loss</span>
<span class="sd">                is obtained as an arithmetic mean across all folds. See [1, 2].</span>

<span class="sd">            `max_coef`:</span>
<span class="sd">                Places an upper bound on the number of non-zero coefficients</span>
<span class="sd">                the selected model returned after cross validation may have.</span>

<span class="sd">                In particular, if `max_coef=k`, during scoring, only models</span>
<span class="sd">                with a total number of non-zero coefficients less than k are</span>
<span class="sd">                considered.</span>

<span class="sd">                Currently, we still calculate the solutions for these</span>
<span class="sd">                models, we just disregard them at scoring time.</span>

<span class="sd">            `alpha_type`:</span>
<span class="sd">                Decides how the regularization hyperparameter is selected.</span>
<span class="sd">                For a given `cv_score_method` and `max_coef`, we end up with</span>
<span class="sd">                a vector of length k &gt; 1, that contains numeric scores,</span>
<span class="sd">                where lower is better (i.e., losses). `alpha_type` decides</span>
<span class="sd">                how we choose among the regularization hyperparameters corresponding</span>
<span class="sd">                to this loss vector.</span>

<span class="sd">                - `min`: Selects the regularization hyperparameter that</span>
<span class="sd">                yields the minimum loss.</span>

<span class="sd">                - `1se`: Selects the highest regularization hyperparameter</span>
<span class="sd">                that is within one standard error of the mean loss of the</span>
<span class="sd">                regularization hyperparameter with minimum loss [3].</span>

<span class="sd">                - `pcvl`: Selects a hyperparameter inbetween `min` and</span>
<span class="sd">                `1se` via a penalization term. See [4].</span>



<span class="sd">        References:</span>
<span class="sd">            [1] Dai, Biyue, and Patrick Breheny. &quot;Cross validation approaches for penalized Cox regression.&quot; arXiv preprint arXiv:1905.10432 (2019).</span>

<span class="sd">            [2] Verweij, Pierre JM, and Hans C. Van Houwelingen. &quot;Cross‐validation in survival analysis.&quot; Statistics in medicine 12.24 (1993): 2305-2314.</span>

<span class="sd">            [3] Hastie, Trevor, et al. The elements of statistical learning: data mining, inference, and prediction. Vol. 2. New York: Springer, 2009.</span>

<span class="sd">            [4] Ternès, Nils, Federico Rotolo, and Stefan Michiels. &quot;Empirical extensions of the lasso penalty to reduce the false discovery rate in high‐dimensional Cox regression models.&quot; Statistics in medicine 35.15 (2016): 2561-2573.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
            <span class="n">eps</span><span class="o">=</span><span class="n">eps</span><span class="p">,</span>
            <span class="n">n_alphas</span><span class="o">=</span><span class="n">n_alphas</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">p0</span><span class="o">=</span><span class="n">p0</span><span class="p">,</span>
            <span class="n">prune</span><span class="o">=</span><span class="n">prune</span><span class="p">,</span>
            <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span>
            <span class="n">stratify_cv</span><span class="o">=</span><span class="n">stratify_cv</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">shuffle_cv</span><span class="o">=</span><span class="n">shuffle_cv</span><span class="p">,</span>
            <span class="n">cv_score_method</span><span class="o">=</span><span class="n">cv_score_method</span><span class="p">,</span>
            <span class="n">max_coef</span><span class="o">=</span><span class="n">max_coef</span><span class="p">,</span>
            <span class="n">alpha_type</span><span class="o">=</span><span class="n">alpha_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bandwidth</span> <span class="o">=</span> <span class="n">bandwidth</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">LOSS_FACTORY</span><span class="p">[</span><span class="s2">&quot;eh&quot;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span> <span class="o">=</span> <span class="n">BASELINE_HAZARD_FACTORY</span><span class="p">[</span><span class="s2">&quot;eh&quot;</span><span class="p">]</span></div>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV.path"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV.path">[docs]</a>    <span class="k">def</span> <span class="nf">path</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">coef_init</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute Lasso path with Celer. Function taken as-is from celer for compatibility</span>
<span class="sd">            with parent class.</span>

<span class="sd">        See Also:</span>
<span class="sd">            celer.homotopy.mtl_path</span>
<span class="sd">            celer.dropin_sklearn.MultiTaskLassoCV</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">dual_gaps</span> <span class="o">=</span> <span class="n">celer</span><span class="o">.</span><span class="n">homotopy</span><span class="o">.</span><span class="n">mtl_path</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">y</span><span class="p">,</span>
            <span class="n">alphas</span><span class="o">=</span><span class="n">alphas</span><span class="p">,</span>
            <span class="n">coef_init</span><span class="o">=</span><span class="n">coef_init</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">,</span>
            <span class="n">p0</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">p0</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">prune</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">prune</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">alphas</span><span class="p">,</span> <span class="n">coefs</span><span class="p">,</span> <span class="n">dual_gaps</span></div>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV.predict"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV.predict">[docs]</a>    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Calculate linear predictor corresponding to query design matrix X.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Query design matrix.</span>

<span class="sd">        Returns:</span>
<span class="sd">            npt.NDArray[np.float64]: Linear predictor of the samples.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">X</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span></div>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV._is_multitask"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV._is_multitask">[docs]</a>    <span class="k">def</span> <span class="nf">_is_multitask</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Return whether the model instance in question is a multitask model.</span>

<span class="sd">        Needed for scikit-learn/celer compatability.</span>

<span class="sd">        Returns:</span>
<span class="sd">            bool</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="kc">True</span></div>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV._get_estimator"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV._get_estimator">[docs]</a>    <span class="k">def</span> <span class="nf">_get_estimator</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">celer</span><span class="o">.</span><span class="n">MultiTaskLasso</span><span class="p">()</span></div>

<div class="viewcode-block" id="KDEHMultiTaskLassoCV.predict_cumulative_hazard_function"><a class="viewcode-back" href="../../sparsesurv_api/sparsesurv.cv.html#sparsesurv.cv.KDEHMultiTaskLassoCV.predict_cumulative_hazard_function">[docs]</a>    <span class="k">def</span> <span class="nf">predict_cumulative_hazard_function</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">],</span> <span class="n">time</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Predict cumulative hazard function for patients in `X` at times `time`.</span>

<span class="sd">        Args:</span>
<span class="sd">            X (npt.NDArray[np.float64]): Query design matrix with u rows and p columns.</span>
<span class="sd">            time (npt.NDArray[np.float64]): Query times of dimension k. Assumed to be unique and ordered.</span>

<span class="sd">        Raises:</span>
<span class="sd">            ValueError: Raises ValueError when the event times are not unique and sorted in ascending order.</span>

<span class="sd">        Returns:</span>
<span class="sd">            npt.NDArray[np.float64]: Query cumulative hazard function for samples 1, ..., u</span>
<span class="sd">                and times 1, ..., k. Thus, has u rows and k columns.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Times for survival and cumulative hazard prediction must be greater than or equal to zero.&quot;</span>
                <span class="o">+</span> <span class="sa">f</span><span class="s2">&quot;Minimum time found was </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">time</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="o">+</span> <span class="s2">&quot;Please remove any times strictly less than zero.&quot;</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">cumulative_baseline_hazard</span><span class="p">(</span>
            <span class="n">time_query</span><span class="o">=</span><span class="n">time</span><span class="p">,</span>
            <span class="n">eta_query</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">),</span>
            <span class="n">time_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_time_</span><span class="p">,</span>
            <span class="n">event_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_event_</span><span class="p">,</span>
            <span class="n">eta_train</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_eta_</span><span class="p">,</span>
        <span class="p">)</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright BoevaLab 2023.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>