{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "069941be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from survhive.cv_models import CoxPHElasticNetCV, CoxPHPrecondCV\n",
    "from survhive.utils import transform_survival, transform_preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04fc657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../config.json\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343b2daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_efron_lasso = {}\n",
    "failures_efron_lasso = {}\n",
    "sparsity_efron_lasso = {}\n",
    "\n",
    "results_efron_elastic_net = {}\n",
    "failures_efron_elastic_net = {}\n",
    "sparsity_efron_elastic_net = {}\n",
    "\n",
    "results_efron_precond = {}\n",
    "failures_efron_precond = {}\n",
    "sparsity_efron_precond = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77df313d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    CoxPHElasticNetCV(tie_correction=\"efron\",\n",
    "                     eps=0.05,\n",
    "                      n_alphas=100,\n",
    "                      l1_ratios=[1.0],\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      random_state=config[\"random_state\"],\n",
    "                      n_irls_iter=5,\n",
    "                      tol=0.0001\n",
    "                     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "615d5848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: BLCA\n",
      "Starting split: 1 / 25\n",
      "Starting split: 2 / 25\n",
      "Starting split: 3 / 25\n",
      "Starting split: 4 / 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/slightlier/miniforge3/envs/sparsesurv_dev/lib/python3.10/multiprocessing/util.py\", line 218, in __call__\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m     failures_efron_lasso[cancer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     sparsity_efron_lasso[cancer][split] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(pipe_efron[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mcoef_ \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     22\u001b[0m     results_efron_lasso[cancer][split] \u001b[38;5;241m=\u001b[39m pipe_efron\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/site-packages/sklearn/pipeline.py:405\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    404\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 405\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/20230427/survhive/survhive/cv.py:1040\u001b[0m, in \u001b[0;36mRegularizedLinearSurvivalModelCV.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1021\u001b[0m best_pl_score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n\u001b[1;32m   1023\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1024\u001b[0m     delayed(alpha_path_eta)(\n\u001b[1;32m   1025\u001b[0m         X\u001b[38;5;241m=\u001b[39mX_sorted,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[1;32m   1039\u001b[0m )\n\u001b[0;32m-> 1040\u001b[0m eta_path \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;66;03m# TODO DW: Since we're not using train eta now,\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;66;03m# we can actually remove this.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m train_eta_folds, test_eta_folds, _, test_y_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39meta_path)\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniforge3/envs/sparsesurv_dev/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for cancer in config[\"datasets\"]:\n",
    "    print(f\"Starting: {cancer}\")\n",
    "    train_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_train_splits.csv\")\n",
    "    test_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_test_splits.csv\")\n",
    "    data = pd.read_csv(f\"../data/processed/TCGA/{cancer}_data_preprocessed.csv\").iloc[:, 1:]\n",
    "    X_ = data.iloc[:, 3:]\n",
    "    y_ = transform_survival(time=data[\"OS_days\"].values, event=data[\"OS\"].values)\n",
    "    for split in range(25):\n",
    "        print(f\"Starting split: {split+1} / 25\")\n",
    "        train_ix = train_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        test_ix = test_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        X_train = X_.iloc[train_ix, :].copy().reset_index(drop=True)\n",
    "        y_train = y_[train_ix].copy()\n",
    "        X_test = X_.iloc[test_ix, :].copy().reset_index(drop=True)\n",
    "        if split == 0:\n",
    "            results_efron_lasso[cancer] = {}\n",
    "            sparsity_efron_lasso[cancer] = {}\n",
    "            failures_efron_lasso[cancer] = 0\n",
    "        try:\n",
    "            pipe.fit(X_train, y_train)\n",
    "            sparsity_efron_lasso[cancer][split] = np.sum(pipe_efron[1].coef_ != 0)\n",
    "            results_efron_lasso[cancer][split] = pipe_efron.predict(X_test)\n",
    "        except ValueError as e:\n",
    "            failures_efron_lasso[cancer] += 1\n",
    "            results_efron_lasso[cancer][split] = np.zeros(test_ix.shape[0])\n",
    "            sparsity_efron_lasso[cancer][split] = 0\n",
    "            \n",
    "    pd.concat([pd.DataFrame(results_efron[cancer][i]) for i in range(25)], axis=1).to_csv(\n",
    "        f\"../results/efron_lasso_{cancer}.csv\", index=False\n",
    "    )\n",
    "    \n",
    "pd.DataFrame(sparsity_efron_lasso).to_csv(\n",
    "    f\"../results/efron_lasso_sparsity.csv\", index=False\n",
    ")\n",
    "pd.DataFrame(failures_efron_lasso).to_csv(\n",
    "    f\"../results/efron_lasso_failures.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fc9eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BLCA\n",
       "0     0\n",
       "1     0\n",
       "2     0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    CoxPHElasticNetCV(tie_correction=\"efron\",\n",
    "                     eps=0.05,\n",
    "                      n_alphas=100,\n",
    "                      l1_ratios=[.1, .5, .7, .9, .95, .99, 1],\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      random_state=config[\"random_state\"],\n",
    "                      n_irls_iter=5,\n",
    "                      tol=0.0001\n",
    "                     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96188f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cancer in config[\"datasets\"]:\n",
    "    print(f\"Starting: {cancer}\")\n",
    "    train_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_train_splits.csv\")\n",
    "    test_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_test_splits.csv\")\n",
    "    data = pd.read_csv(f\"../data/processed/TCGA/{cancer}_data_preprocessed.csv\").iloc[:, 1:]\n",
    "    X_ = data.iloc[:, 3:]\n",
    "    y_ = transform_survival(time=data[\"OS_days\"].values, event=data[\"OS\"].values)\n",
    "    for split in range(25):\n",
    "        print(f\"Starting split: {split+1} / 25\")\n",
    "        train_ix = train_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        test_ix = test_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        X_train = X_.iloc[train_ix, :].copy().reset_index(drop=True)\n",
    "        y_train = y_[train_ix].copy()\n",
    "        X_test = X_.iloc[test_ix, :].copy().reset_index(drop=True)\n",
    "        if split == 0:\n",
    "            results_efron_elastic_net[cancer] = {}\n",
    "            sparsity_efron_elastic_net[cancer] = {}\n",
    "            failures_efron_elastic_net[cancer] = 0\n",
    "        try:\n",
    "            pipe.fit(X_train, y_train)\n",
    "            sparsity_efron_elastic_net[cancer][split] = np.sum(pipe_efron[1].coef_ != 0)\n",
    "            results_efron_elastic_net[cancer][split] = pipe_efron.predict(X_test)\n",
    "        except ValueError as e:\n",
    "            failures_efron_elastic_net[cancer] += 1\n",
    "            results_efron_elastic_net[cancer][split] = np.zeros(test_ix.shape[0])\n",
    "            sparsity_efron_elastic_net[cancer][split] = 0\n",
    "            \n",
    "    pd.concat([pd.DataFrame(results_efron[cancer][i]) for i in range(25)], axis=1).to_csv(\n",
    "        f\"../results/efron_elastic_net_{cancer}.csv\", index=False\n",
    "    )\n",
    "    \n",
    "pd.DataFrame(sparsity_efron_elastic_net).to_csv(\n",
    "    f\"../results/efron_elastic_net_sparsity.csv\", index=False\n",
    ")\n",
    "pd.DataFrame(failures_efron_elastic_net).to_csv(\n",
    "    f\"../results/efron_elastic_net_failures.csv\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f745e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    CoxPHElasticNetCV(tie_correction=\"efron\",\n",
    "                     eps=0.05,\n",
    "                      n_alphas=100,\n",
    "                      taus=[0.0, 0.1, 0.3, 0.5, 0.7, 0.9, 1.0],\n",
    "                      cv=5,\n",
    "                      n_jobs=-1,\n",
    "                      random_state=config[\"random_state\"],\n",
    "                      maxiter=1000,\n",
    "                      rtol=1e-6,\n",
    "                      verbose=0,\n",
    "                      default_step_size=1.0\n",
    "                     )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c236ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cancer in config[\"datasets\"]:\n",
    "    print(f\"Starting: {cancer}\")\n",
    "    train_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_train_splits.csv\")\n",
    "    train_predictions = pd.read_csv(f\"../results/teacher/efron_{cancer}.csv\")\n",
    "    test_splits = pd.read_csv(f\"../data/splits/TCGA/{cancer}_test_splits.csv\")\n",
    "    data = pd.read_csv(f\"../data/processed/TCGA/{cancer}_data_preprocessed.csv\").iloc[:, 1:]\n",
    "    X_ = data.iloc[:, 3:]\n",
    "    for split in range(25):\n",
    "        print(f\"Starting split: {split+1} / 25\")\n",
    "        train_ix = train_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        test_ix = test_splits.iloc[split, :].dropna().to_numpy().astype(int)\n",
    "        X_train = X_.iloc[train_ix, :].copy().reset_index(drop=True)\n",
    "        #y_train = y_[train_ix].copy()\n",
    "        y_train = transform_preconditioning(\n",
    "            time=data[\"OS_days\"].values[train_ix],\n",
    "            event=data[\"OS\"].values[train_ix],\n",
    "            y_teacher=train_predictions.iloc[:, split].dropna().values\n",
    "        )\n",
    "        X_test = X_.iloc[test_ix, :].copy().reset_index(drop=True)\n",
    "        if split == 0:\n",
    "            results_efron_precond[cancer] = {}\n",
    "            sparsity_efron_precond[cancer] = {}\n",
    "            failures_efron_precond[cancer] = 0\n",
    "        try:\n",
    "            pipe.fit(X_train, y_train)\n",
    "            sparsity_efron_precond[cancer][split] = np.sum(pipe_efron[1].coef_ != 0)\n",
    "            results_efron_precond[cancer][split] = pipe_efron.predict(X_test)\n",
    "        except ValueError as e:\n",
    "            failures_efron_precond[cancer] += 1\n",
    "            results_efron_precond[cancer][split] = np.zeros(test_ix.shape[0])\n",
    "            sparsity_efron_precond[cancer][split] = 0\n",
    "            \n",
    "    pd.concat([pd.DataFrame(results_efron[cancer][i]) for i in range(25)], axis=1).to_csv(\n",
    "        f\"../results/efron_precond_{cancer}.csv\", index=False\n",
    "    )\n",
    "    \n",
    "pd.DataFrame(sparsity_efron_precond).to_csv(\n",
    "    f\"../results/efron_precond_sparsity.csv\", index=False\n",
    ")\n",
    "pd.DataFrame(failures_efron_precond).to_csv(\n",
    "    f\"../results/efron_precond_failures.csv\", index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
